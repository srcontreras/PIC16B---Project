{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b9041b4b-4288-42d5-a6db-67127b6051e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/sarah/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import tensorflow as tf\n",
    "\n",
    "# for model \n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from textblob import Word\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "556c7a2e-060a-4f0f-aee2-112092c23dd5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Butler University Creates 2-Year Debt-Free Col...</td>\n",
       "      <td>Butler University of Indianapolis has created ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Since Pandemic Closed His Business, New Jersey...</td>\n",
       "      <td>The owner of a New Jersey frame shop has been ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PayPal Commits Over $500 Million to Support Mi...</td>\n",
       "      <td>PayPal yesterday announced a $530 million comm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9-Year-Old and Friends Have Raised $100,000 fo...</td>\n",
       "      <td>Some unlikely heroes in Minneapolis have raise...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hanes is Equipping America’s Homeless With 1 M...</td>\n",
       "      <td>Hanes basic apparel is not only encouraging Am...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Butler University Creates 2-Year Debt-Free Col...   \n",
       "1  Since Pandemic Closed His Business, New Jersey...   \n",
       "2  PayPal Commits Over $500 Million to Support Mi...   \n",
       "3  9-Year-Old and Friends Have Raised $100,000 fo...   \n",
       "4  Hanes is Equipping America’s Homeless With 1 M...   \n",
       "\n",
       "                                             content  \n",
       "0  Butler University of Indianapolis has created ...  \n",
       "1  The owner of a New Jersey frame shop has been ...  \n",
       "2  PayPal yesterday announced a $530 million comm...  \n",
       "3  Some unlikely heroes in Minneapolis have raise...  \n",
       "4  Hanes basic apparel is not only encouraging Am...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in good news data\n",
    "df = pd.read_csv(\"articles.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "310e6fd8-819c-46f1-8962-bd5d2f329eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up the content from the good news articles\n",
    "def clean_news(input_data):\n",
    "    \"\"\"\n",
    "    This function transforms the text to all lowercase letters and removes special punctuation\n",
    "    input: text data\n",
    "    output: standardized string\n",
    "    \"\"\"\n",
    "    lowercase = tf.strings.lower(input_data)\n",
    "    no_punctuation = tf.strings.regex_replace(lowercase,\n",
    "                                  '[%s]' % re.escape(string.punctuation),'')\n",
    "    return no_punctuation.numpy().decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ae5cff00-7a32-44a6-94d5-2d4eae2931e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Butler University Creates 2-Year Debt-Free Col...</td>\n",
       "      <td>butler university of indianapolis has created ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Since Pandemic Closed His Business, New Jersey...</td>\n",
       "      <td>the owner of a new jersey frame shop has been ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PayPal Commits Over $500 Million to Support Mi...</td>\n",
       "      <td>paypal yesterday announced a 530 million commi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9-Year-Old and Friends Have Raised $100,000 fo...</td>\n",
       "      <td>some unlikely heroes in minneapolis have raise...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hanes is Equipping America’s Homeless With 1 M...</td>\n",
       "      <td>hanes basic apparel is not only encouraging am...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Butler University Creates 2-Year Debt-Free Col...   \n",
       "1  Since Pandemic Closed His Business, New Jersey...   \n",
       "2  PayPal Commits Over $500 Million to Support Mi...   \n",
       "3  9-Year-Old and Friends Have Raised $100,000 fo...   \n",
       "4  Hanes is Equipping America’s Homeless With 1 M...   \n",
       "\n",
       "                                             content  \n",
       "0  butler university of indianapolis has created ...  \n",
       "1  the owner of a new jersey frame shop has been ...  \n",
       "2  paypal yesterday announced a 530 million commi...  \n",
       "3  some unlikely heroes in minneapolis have raise...  \n",
       "4  hanes basic apparel is not only encouraging am...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# standardize the content \n",
    "df['content'] = df['content'].apply(clean_news)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "484efca2-bb4c-48b1-acb4-cbe526672101",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2487, 2)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1921edaa-f5da-447a-9bd3-2036b6b5418b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ** MODEL 1 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2f886ff8-a7d7-4cfd-baf2-b8920b0d918e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The GeoSolutions technology will leverage Bene...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$ESI on lows, down $1.50 to $2.50 BK a real po...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>For the last quarter of 2010 , Componenta 's n...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>According to the Finnish-Russian Chamber of Co...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Swedish buyout firm has sold its remaining...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence Sentiment\n",
       "0  The GeoSolutions technology will leverage Bene...  positive\n",
       "1  $ESI on lows, down $1.50 to $2.50 BK a real po...  negative\n",
       "2  For the last quarter of 2010 , Componenta 's n...  positive\n",
       "3  According to the Finnish-Russian Chamber of Co...   neutral\n",
       "4  The Swedish buyout firm has sold its remaining...   neutral"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load financial sentiment analysis data\n",
    "# https://www.kaggle.com/datasets/sbhatti/financial-sentiment-analysis\n",
    "# data provides a column for financial sentences \n",
    "# and a column for sentiment ('positive', 'negative', or 'neutral')\n",
    "fin_data = pd.read_csv(\"fin_data.csv\")\n",
    "fin_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "21e4f133-5257-4129-af6f-e430f3255000",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5842, 2)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f3343ac6-19fe-4219-8779-fd18e0f2a665",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "db162287-6257-40c0-8016-c4ab8a3d3980",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def standardization(df, stop_words):\n",
    "    # transforms text to lowercase letters\n",
    "    df['Sentence'] = df['Sentence'].apply(lambda x: ' '.join(x.lower() for x in x.split()))\n",
    "    # remove digits \n",
    "    df['Sentence'] = df['Sentence'].str.replace('\\d', '')\n",
    "    # removes stop words for each word in Sentence column\n",
    "    df['Sentence'] = df['Sentence'].apply(lambda x: ' '.join(x for x in x.split() if x not in stop_words))\n",
    "    # lemmatization: reduce inflected words to root form for each word in Sentence column\n",
    "    df['Sentence'] = df['Sentence'].apply(lambda x: ' '.join([Word(x).lemmatize() for x in x.split()]))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "46c88144-a05b-479d-9eb2-6129c107f7c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>geosolutions technology leverage benefon 's gp...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$esi lows, $1.50 $2.50 bk real possibility</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>last quarter 2010 , componenta 's net sale dou...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>according finnish-russian chamber commerce , m...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>swedish buyout firm sold remaining 22.4 percen...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence Sentiment\n",
       "0  geosolutions technology leverage benefon 's gp...  positive\n",
       "1         $esi lows, $1.50 $2.50 bk real possibility  negative\n",
       "2  last quarter 2010 , componenta 's net sale dou...  positive\n",
       "3  according finnish-russian chamber commerce , m...   neutral\n",
       "4  swedish buyout firm sold remaining 22.4 percen...   neutral"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "fin_data = standardization(fin_data, stop_words)\n",
    "fin_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "74facff7-bfbd-4dc2-b5cb-d932f012ff8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# issue: not removing digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2337d6e2-aa55-4348-befa-0d758de0b27d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add code to split data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7fc7900a-8446-4dad-a39d-aeff1962679b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# use tokenizer to vectorize words into list of integers\n",
    "max_num = 2000 # top 2000 common words in data\n",
    "tokenizer = Tokenizer(num_words = max_num, split = ' ') \n",
    "tokenizer.fit_on_texts(fin_data['Sentence'].values)\n",
    "# convert Sentence column into sequence of integers\n",
    "X = tokenizer.texts_to_sequences(fin_data['Sentence'].values)\n",
    "# ensures equal length\n",
    "X = pad_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9d0162b4-c16f-4885-a3c2-dd2c4ac23ffb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model1 = tf.keras.Sequential([\n",
    "    layers.Embedding(max_num, output_dim = 120),\n",
    "    layers.SpatialDropout1D(0.4),\n",
    "    layers.LSTM(704, dropout=0.2, recurrent_dropout=0.2),\n",
    "    layers.Dense(352, activation='LeakyReLU'),\n",
    "    layers.Dense(3, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "48c72636-3fe9-4593-8feb-3feb3004ef32",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, None, 120)         240000    \n",
      "                                                                 \n",
      " spatial_dropout1d_1 (Spati  (None, None, 120)         0         \n",
      " alDropout1D)                                                    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 704)               2323200   \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 352)               248160    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3)                 1059      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2812419 (10.73 MB)\n",
      "Trainable params: 2812419 (10.73 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f25ea8-1b0a-4023-baf2-978e203ff4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "model.fit(X_train, y_train, epochs = 20, batch_size=32, verbose =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209bd424-56aa-4323-bebf-1b174ee043b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
